<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">=pytest_report.html</title>
      <link href="assets\style.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <h1 id="title">=pytest_report.html</h1>
    <p>Report generated on 24-Apr-2025 at 14:01:49 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">40 tests took 00:19:07.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">3 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">37 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.11.9&#34;, &#34;Platform&#34;: &#34;Windows-10-10.0.26100-SP0&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.3.4&#34;, &#34;pluggy&#34;: &#34;1.5.0&#34;}, &#34;Plugins&#34;: {&#34;Faker&#34;: &#34;37.1.0&#34;, &#34;cov&#34;: &#34;6.0.0&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;}}, &#34;tests&#34;: {&#34;tests/test_against_condition_changes.py::test_reducing_helo_resource&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_reducing_helo_resource&#34;, &#34;duration&#34;: &#34;00:01:46&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_reducing_helo_resource&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:46&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;------------------------------ Captured log setup ------------------------------\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.address`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.address` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.automotive`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.automotive` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.bank`.\nDEBUG    faker.factory:factory.py:88 Specified locale `en_US` is not available for provider `faker.providers.bank`. Locale reset to `en_GB` for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.barcode`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.barcode` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.color`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.color` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.company`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.company` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.credit_card`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.credit_card` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.currency`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.currency` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.date_time`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.date_time` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.doi` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.emoji` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.file` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.geo`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.geo` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.internet`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.internet` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.isbn`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.isbn` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.job`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.job` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.lorem`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.lorem` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.misc`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.misc` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.passport`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.passport` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.person`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.person` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.phone_number`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.phone_number` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.profile` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.python` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.sbn` does not feature localization. Specified locale `en_US` is not utilized for this provider.\nDEBUG    faker.factory:factory.py:78 Looking for locale `en_US` in provider `faker.providers.ssn`.\nDEBUG    faker.factory:factory.py:97 Provider `faker.providers.ssn` has been localized to `en_US`.\nDEBUG    faker.factory:factory.py:108 Provider `faker.providers.user_agent` does not feature localization. Specified locale `en_US` is not utilized for this provider.\n\n----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_no_solo_car&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_no_solo_car&#34;, &#34;duration&#34;: &#34;00:02:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_no_solo_car&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:02:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_shorter_operating_hours&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_shorter_operating_hours&#34;, &#34;duration&#34;: &#34;00:01:49&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_shorter_operating_hours&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:49&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_longer_operating_hours&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_longer_operating_hours&#34;, &#34;duration&#34;: &#34;00:01:55&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_longer_operating_hours&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:01:55&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_extra_solo_car&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_extra_solo_car&#34;, &#34;duration&#34;: &#34;00:02:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_extra_solo_car&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:02:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_extra_helo&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_extra_helo&#34;, &#34;duration&#34;: &#34;00:02:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_extra_helo&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:02:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n5           6  ...             True\n6           7  ...             True\n7           8  ...             True\n8           9  ...             True\n9          10  ...             True\n\n[10 rows x 4 columns]\n&#34;}], &#34;tests/test_against_condition_changes.py::test_changed_helo_model&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_condition_changes.py::test_changed_helo_model&#34;, &#34;duration&#34;: &#34;00:03:37&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_condition_changes.py::test_changed_helo_model&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:03:37&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n   run_number  ...  expected_result\n0           1  ...             True\n1           2  ...             True\n2           3  ...             True\n3           4  ...             True\n4           5  ...             True\n\n[5 rows x 4 columns]\n&#34;}], &#34;tests/test_against_reality.py::test_average_daily_calls_in_period&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_average_daily_calls_in_period&#34;, &#34;duration&#34;: &#34;00:02:34&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_average_daily_calls_in_period&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:02:34&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stdout setup -----------------------------\nGenerating simulation results...\n&#34;}], &#34;tests/test_against_reality.py::test_distribution_daily_calls&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_distribution_daily_calls&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_distribution_daily_calls&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_against_reality.py::test_average_total_job_durations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_average_total_job_durations&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_average_total_job_durations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_against_reality.py::test_distribution_total_job_durations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_distribution_total_job_durations&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_distribution_total_job_durations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_against_reality.py::test_proportions_callsigngroup_allocations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_proportions_callsigngroup_allocations&#34;, &#34;duration&#34;: &#34;111 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_proportions_callsigngroup_allocations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;111 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\nResult: Reject the null hypothesis (H\u2080) for callsign group.\nConclusion: There is a statistically significant difference in the distribution of callsigns between the simulated and historic data.\nTotal Observations (n): 100619.0\nCram\u00e9r&amp;#x27;s V (Effect Size): 0.0389\n&#34;}], &#34;tests/test_against_reality.py::test_proportions_callsign_allocations&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_against_reality.py::test_proportions_callsign_allocations&#34;, &#34;duration&#34;: &#34;101 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_against_reality.py::test_proportions_callsign_allocations&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;101 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;simulation_results =          Unnamed: 0   P_ID  run_number time_type                         event_type  timestamp                timestam...            NaN         09  84.0  Male       EC            y         NaN      NaN      NaN\n\n[1614497 rows x 25 columns]\n\n    @pytest.mark.callsign\n    def test_proportions_callsign_allocations(simulation_results):\n        # Calculate proportion of jobs allocated to each callsign in the simulation\n        callsign_counts_simulated = simulation_results[simulation_results[&amp;quot;event_type&amp;quot;]==&amp;quot;resource_use&amp;quot;][&amp;quot;callsign&amp;quot;].value_counts().reset_index(name=&amp;quot;count_simulated&amp;quot;)\n        # callsign_counts[&amp;quot;proportion_simulated&amp;quot;] = callsign_counts[&amp;quot;count_simulated&amp;quot;].apply(lambda x: x/callsign_counts[&amp;quot;count_simulated&amp;quot;].sum())\n    \n        # Read in the proportion of jobs allocated to each callsign group in historical data\n        callsign_counts_historic = (\n            pd.read_csv(&amp;quot;historical_data/historical_monthly_totals_by_callsign.csv&amp;quot;)\n            .drop(columns=&amp;quot;month&amp;quot;)\n            .sum()\n            .reset_index(name=&amp;quot;count_historic&amp;quot;)\n            )\n        callsign_counts_historic.rename(columns={&amp;#x27;index&amp;#x27;:&amp;#x27;callsign&amp;#x27;}, inplace=True)\n    \n        callsign_counts = callsign_counts_simulated.merge(callsign_counts_historic, on=&amp;quot;callsign&amp;quot;)\n    \n        # Calculate\n&amp;gt;       calculate_chi_squared_and_cramers(callsign_counts, what=&amp;quot;callsign&amp;quot;)\n\ntests\\test_against_reality.py:402: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\helpers.py:93: in calculate_chi_squared_and_cramers\n    fail_with_message(f&amp;quot;One category differs in proportion by more than 10% (found {max_diff:.4f}).\\n\\n{df}&amp;quot;)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nmessage = &amp;#x27;One category differs in proportion by more than 10% (found 0.1294).\\n\\n  callsign  count_simulated  ...  prop_histori...18477  ...       0.127034  0.065044\\n4     CC71             4114  ...       0.056962  0.014195\\n\\n[5 rows x 6 columns]&amp;#x27;\n\n    def fail_with_message(message: str):\n        &amp;quot;&amp;quot;&amp;quot;Cleanly formatted pytest failure message.&amp;quot;&amp;quot;&amp;quot;\n&amp;gt;       pytest.fail(textwrap.dedent(message))\nE       Failed: One category differs in proportion by more than 10% (found 0.1294).\nE       \nE         callsign  count_simulated  ...  prop_historic  abs_diff\nE       0      H70            30778  ...       0.449367  0.129413\nE       1     CC70            22953  ...       0.203210  0.035399\nE       2     CC72            19873  ...       0.163427  0.043164\nE       3      H71            18477  ...       0.127034  0.065044\nE       4     CC71             4114  ...       0.056962  0.014195\nE       \nE       [5 rows x 6 columns]\n\ntests\\helpers.py:9: Failed\n\n----------------------------- Captured stdout call -----------------------------\nResult: Reject the null hypothesis (H\u2080) for callsign.\nConclusion: There is a statistically significant difference in the distribution of callsigns between the simulated and historic data.\nTotal Observations (n): 100619.0\nCram\u00e9r&amp;#x27;s V (Effect Size): 0.0625\n&#34;}], &#34;tests/test_reproducibility.py::test_results_differ_across_runs_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_results_differ_across_runs_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_results_differ_across_runs_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:00:50: Demand increase set to 100.0%\n14:00:50: Run 2 of 1\n14:00:51: Run 2 took 0.0 minutes to run\n14:00:51: Demand increase set to 100.0%\n14:00:51: Run 2 of 1\n14:00:52: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:00:50: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:50: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:51: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:00:51: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:51: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:52: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_results_differ_across_runs_parallelProcessJobLib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_results_differ_across_runs_parallelProcessJobLib&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_results_differ_across_runs_parallelProcessJobLib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:00:53: Demand increase set to 100.0%\n14:00:53: Run 2 of 1\n14:00:53: Run 2 took 0.0 minutes to run\n14:00:53: Demand increase set to 100.0%\n14:00:53: Run 2 of 1\n14:00:54: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:00:53: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:53: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:53: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:00:53: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:53: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:54: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_seed_gives_different_arrival_pattern_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_day_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_day_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_day_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:00:56: Demand increase set to 100.0%\n14:00:56: Run 2 of 1\n14:00:57: Run 2 took 0.0 minutes to run\n14:00:57: Demand increase set to 100.0%\n14:00:57: Run 2 of 1\n14:00:57: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:00:56: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:56: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:57: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:00:57: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:57: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:57: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_hour_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_hour_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_calls_per_hour_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:00:57: Demand increase set to 100.0%\n14:00:57: Run 2 of 1\n14:00:58: Run 2 took 0.0 minutes to run\n14:00:58: Demand increase set to 100.0%\n14:00:58: Run 2 of 1\n14:00:59: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:00:57: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:57: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:58: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:00:58: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:58: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:00:59: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_runSim&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:00:59: Demand increase set to 100.0%\n14:00:59: Run 2 of 1\n14:01:00: Run 2 took 0.0 minutes to run\n14:01:00: Demand increase set to 100.0%\n14:01:00: Run 2 of 1\n14:01:00: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:00:59: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:00:59: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:00: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:00: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:00: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:00: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_different_arrival_pattern_across_runs_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_arrival_pattern_across_runs_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;911 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_arrival_pattern_across_runs_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;911 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:03: Demand increase set to 100.0%\n14:01:03: Run 2 of 1\n14:01:04: Run 2 took 0.0 minutes to run\n14:01:04: Demand increase set to 100.0%\n14:01:04: Run 2 of 1\n14:01:04: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:03: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:03: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:04: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:04: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:04: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:04: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_arrival_pattern_VARYING_PARAMETERS_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_pattern_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_pattern_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_pattern_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:06: Demand increase set to 100.0%\n14:01:06: Run 2 of 1\n14:01:07: Run 2 took 0.0 minutes to run\n14:01:07: Demand increase set to 100.0%\n14:01:07: Run 2 of 1\n14:01:07: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:06: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:06: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:07: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:07: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:07: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:07: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_same_seed_gives_consistent_results_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_different_seed_gives_different_results_pattern_runSim&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_seed_gives_different_results_pattern_runSim&#34;, &#34;duration&#34;: &#34;00:00:01&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_seed_gives_different_results_pattern_runSim&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:01&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:09: Demand increase set to 100.0%\n14:01:09: Run 2 of 1\n14:01:10: Run 2 took 0.0 minutes to run\n14:01:10: Demand increase set to 100.0%\n14:01:10: Run 2 of 1\n14:01:10: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:09: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:09: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:10: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:10: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:10: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:10: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_reproducibility.py::test_different_seed_gives_different_results_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_seed_gives_different_results_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_seed_gives_different_results_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_reproducibility.py::test_different_result_pattern_across_runs_parallelProcessJoblib&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_reproducibility.py::test_different_result_pattern_across_runs_parallelProcessJoblib&#34;, &#34;duration&#34;: &#34;989 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_reproducibility.py::test_different_result_pattern_across_runs_parallelProcessJoblib&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;989 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_unittest_model.py::test_model_runs&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_model_runs&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_model_runs&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_unittest_model.py::test_more_results_for_longer_run&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_more_results_for_longer_run&#34;, &#34;duration&#34;: &#34;00:00:16&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_more_results_for_longer_run&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:16&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:15: Demand increase set to 100.0%\n14:01:15: Run 2 of 1\n14:01:15: Run 2 took 0.0 minutes to run\n14:01:15: Demand increase set to 100.0%\n14:01:15: Run 2 of 1\n14:01:16: Run 2 took 0.0 minutes to run\n14:01:16: Demand increase set to 100.0%\n14:01:16: Run 2 of 1\n14:01:17: Run 2 took 0.0 minutes to run\n14:01:17: Demand increase set to 100.0%\n14:01:17: Run 2 of 1\n14:01:18: Run 2 took 0.0 minutes to run\n14:01:18: Demand increase set to 100.0%\n14:01:18: Run 2 of 1\n14:01:19: Run 2 took 0.0 minutes to run\n14:01:19: Demand increase set to 100.0%\n14:01:19: Run 2 of 1\n14:01:20: Run 2 took 0.0 minutes to run\n14:01:20: Demand increase set to 100.0%\n14:01:20: Run 2 of 1\n14:01:20: Run 2 took 0.0 minutes to run\n14:01:20: Demand increase set to 100.0%\n14:01:20: Run 2 of 1\n14:01:21: Run 2 took 0.0 minutes to run\n14:01:21: Demand increase set to 100.0%\n14:01:21: Run 2 of 1\n14:01:22: Run 2 took 0.0 minutes to run\n14:01:22: Demand increase set to 100.0%\n14:01:22: Run 2 of 1\n14:01:23: Run 2 took 0.0 minutes to run\n14:01:23: Demand increase set to 100.0%\n14:01:23: Run 2 of 1\n14:01:23: Run 2 took 0.0 minutes to run\n14:01:23: Demand increase set to 100.0%\n14:01:23: Run 2 of 1\n14:01:24: Run 2 took 0.0 minutes to run\n14:01:24: Demand increase set to 100.0%\n14:01:24: Run 2 of 1\n14:01:25: Run 2 took 0.0 minutes to run\n14:01:25: Demand increase set to 100.0%\n14:01:25: Run 2 of 1\n14:01:26: Run 2 took 0.0 minutes to run\n14:01:26: Demand increase set to 100.0%\n14:01:26: Run 2 of 1\n14:01:27: Run 2 took 0.0 minutes to run\n14:01:27: Demand increase set to 100.0%\n14:01:27: Run 2 of 1\n14:01:28: Run 2 took 0.0 minutes to run\n14:01:28: Demand increase set to 100.0%\n14:01:28: Run 2 of 1\n14:01:28: Run 2 took 0.0 minutes to run\n14:01:28: Demand increase set to 100.0%\n14:01:28: Run 2 of 1\n14:01:29: Run 2 took 0.0 minutes to run\n14:01:29: Demand increase set to 100.0%\n14:01:29: Run 2 of 1\n14:01:30: Run 2 took 0.0 minutes to run\n14:01:30: Demand increase set to 100.0%\n14:01:30: Run 2 of 1\n14:01:31: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:15: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:15: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:15: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:15: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:15: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:16: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:16: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:16: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:17: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:17: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:17: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:18: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:18: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:18: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:19: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:19: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:19: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:20: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:20: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:20: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:20: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:20: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:20: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:21: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:21: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:21: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:22: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:22: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:22: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:23: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:23: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:23: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:23: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:23: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:23: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:24: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:24: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:24: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:25: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:25: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:25: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:26: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:26: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:26: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:27: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:27: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:27: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:28: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:28: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:28: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:28: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:28: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:28: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:29: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:29: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:29: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:30: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:30: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:30: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:31: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_unittest_model.py::test_arrivals_increase_if_demand_param_increased&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_arrivals_increase_if_demand_param_increased&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_arrivals_increase_if_demand_param_increased&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:31: Demand increase set to 100.0%\n14:01:31: Run 2 of 1\n14:01:31: Run 2 took 0.0 minutes to run\n14:01:31: Demand increase set to 120.0%\n14:01:31: Run 2 of 1\n14:01:32: Run 2 took 0.0 minutes to run\n14:01:32: Demand increase set to 100.0%\n14:01:32: Run 2 of 1\n14:01:33: Run 2 took 0.0 minutes to run\n14:01:33: Demand increase set to 120.0%\n14:01:33: Run 2 of 1\n14:01:33: Run 2 took 0.0 minutes to run\n14:01:33: Demand increase set to 100.0%\n14:01:33: Run 2 of 1\n14:01:34: Run 2 took 0.0 minutes to run\n14:01:34: Demand increase set to 120.0%\n14:01:34: Run 2 of 1\n14:01:35: Run 2 took 0.0 minutes to run\n14:01:35: Demand increase set to 100.0%\n14:01:35: Run 2 of 1\n14:01:35: Run 2 took 0.0 minutes to run\n14:01:35: Demand increase set to 120.0%\n14:01:35: Run 2 of 1\n14:01:36: Run 2 took 0.0 minutes to run\n14:01:36: Demand increase set to 100.0%\n14:01:36: Run 2 of 1\n14:01:36: Run 2 took 0.0 minutes to run\n14:01:36: Demand increase set to 120.0%\n14:01:36: Run 2 of 1\n14:01:37: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:31: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:31: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:31: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:31: Demand increase set to 120.0%\nDEBUG    root:des_parallel_process.py:151 14:01:31: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:32: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:32: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:32: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:33: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:33: Demand increase set to 120.0%\nDEBUG    root:des_parallel_process.py:151 14:01:33: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:33: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:33: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:33: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:34: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:34: Demand increase set to 120.0%\nDEBUG    root:des_parallel_process.py:151 14:01:34: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:35: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:35: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:35: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:35: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:35: Demand increase set to 120.0%\nDEBUG    root:des_parallel_process.py:151 14:01:35: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:36: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:36: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:36: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:36: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:36: Demand increase set to 120.0%\nDEBUG    root:des_parallel_process.py:151 14:01:36: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:37: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_unittest_model.py::test_arrivals_decrease_if_demand_param_decrease&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_arrivals_decrease_if_demand_param_decrease&#34;, &#34;duration&#34;: &#34;00:00:05&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_arrivals_decrease_if_demand_param_decrease&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:05&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:37: Demand increase set to 100.0%\n14:01:37: Run 2 of 1\n14:01:38: Run 2 took 0.0 minutes to run\n14:01:38: Demand increase set to 80.0%\n14:01:38: Run 2 of 1\n14:01:38: Run 2 took 0.0 minutes to run\n14:01:38: Demand increase set to 100.0%\n14:01:38: Run 2 of 1\n14:01:39: Run 2 took 0.0 minutes to run\n14:01:39: Demand increase set to 80.0%\n14:01:39: Run 2 of 1\n14:01:39: Run 2 took 0.0 minutes to run\n14:01:39: Demand increase set to 100.0%\n14:01:39: Run 2 of 1\n14:01:40: Run 2 took 0.0 minutes to run\n14:01:40: Demand increase set to 80.0%\n14:01:40: Run 2 of 1\n14:01:40: Run 2 took 0.0 minutes to run\n14:01:40: Demand increase set to 100.0%\n14:01:40: Run 2 of 1\n14:01:41: Run 2 took 0.0 minutes to run\n14:01:41: Demand increase set to 80.0%\n14:01:41: Run 2 of 1\n14:01:41: Run 2 took 0.0 minutes to run\n14:01:41: Demand increase set to 100.0%\n14:01:41: Run 2 of 1\n14:01:42: Run 2 took 0.0 minutes to run\n14:01:42: Demand increase set to 80.0%\n14:01:42: Run 2 of 1\n14:01:42: Run 2 took 0.0 minutes to run\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:37: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:37: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:38: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:38: Demand increase set to 80.0%\nDEBUG    root:des_parallel_process.py:151 14:01:38: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:38: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:38: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:38: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:39: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:39: Demand increase set to 80.0%\nDEBUG    root:des_parallel_process.py:151 14:01:39: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:39: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:39: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:39: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:40: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:40: Demand increase set to 80.0%\nDEBUG    root:des_parallel_process.py:151 14:01:40: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:40: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:40: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:40: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:41: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:41: Demand increase set to 80.0%\nDEBUG    root:des_parallel_process.py:151 14:01:41: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:41: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:41: Demand increase set to 100.0%\nDEBUG    root:des_parallel_process.py:151 14:01:41: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:42: Run 2 took 0.0 minutes to run\nDEBUG    root:des_parallel_process.py:146 14:01:42: Demand increase set to 80.0%\nDEBUG    root:des_parallel_process.py:151 14:01:42: Run 2 of 1\nDEBUG    root:des_parallel_process.py:167 14:01:42: Run 2 took 0.0 minutes to run\n\n&#34;}], &#34;tests/test_unittest_model.py::test_output_when_no_demand&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_output_when_no_demand&#34;, &#34;duration&#34;: &#34;219 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_output_when_no_demand&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;219 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stdout call -----------------------------\n14:01:42: Demand increase set to 0%\n14:01:42: Run 2 of 1\n\n------------------------------ Captured log call -------------------------------\nDEBUG    root:des_parallel_process.py:146 14:01:42: Demand increase set to 0%\nDEBUG    root:des_parallel_process.py:151 14:01:42: Run 2 of 1\n\n&#34;}], &#34;tests/test_unittest_model.py::test_warmup_only&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_warmup_only&#34;, &#34;duration&#34;: &#34;627 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_warmup_only&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;627 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_unittest_model.py::test_no_results_recorded_from_warmup&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_no_results_recorded_from_warmup&#34;, &#34;duration&#34;: &#34;696 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_no_results_recorded_from_warmup&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;696 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource_group&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource_group&#34;, &#34;duration&#34;: &#34;864 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource_group&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;864 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;simulation_results =          Unnamed: 0   P_ID  run_number time_type                         event_type  timestamp                timestam...            NaN         09  84.0  Male       EC            y         NaN      NaN      NaN\n\n[1614497 rows x 25 columns]\n\n    @pytest.mark.resources\n    def test_simultaneous_allocation_same_resource_group(simulation_results):\n       &amp;quot;&amp;quot;&amp;quot;\n       Ensures no two jobs are allocated to resources from the same resource group at overlapping times.\n    \n       This checks for logical consistency in dispatch logic to prevent simultaneous usage\n       of resources grouped together (e.g., mutually exclusive vehicles).\n    \n       In the simulation, where a helicopter and car belong to the same resource group, it is assumed\n       that they can never be running at the same time due to the presence of a single crew crewing\n       that single vehicle.\n    \n       For this reason, we are joining on callsign rather than registration (as when H71 is\n       reallocated temporarily to H70, we need to continue to check that CC70 and the temporary\n       H70 are not running simultaneously).\n       &amp;quot;&amp;quot;&amp;quot;\n       try:\n          removeExistingResults(remove_run_results_csv=True)\n    \n          # Remove existing failure log if it exists\n          if os.path.exists(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FAILURES.csv&amp;quot;):\n             os.remove(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FAILURES.csv&amp;quot;)\n    \n          if os.path.exists(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FULL.csv&amp;quot;):\n                os.remove(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FULL.csv&amp;quot;)\n    \n          results = simulation_results # defined in conftest.py\n    \n          # Extract start and end times of resource usage\n          resource_use_start_and_end = (\n             results[results[&amp;quot;event_type&amp;quot;].isin([&amp;quot;resource_use&amp;quot;,&amp;quot;resource_use_end&amp;quot;])]\n             [[&amp;#x27;P_ID&amp;#x27;,&amp;#x27;run_number&amp;#x27;,&amp;#x27;event_type&amp;#x27;,&amp;#x27;callsign&amp;#x27;,&amp;#x27;callsign_group&amp;#x27;,&amp;#x27;timestamp_dt&amp;#x27;,&amp;quot;registration&amp;quot;]]\n             )\n    \n          # Merge start and end events into single row per job\n          resource_use_start = (\n             resource_use_start_and_end[resource_use_start_and_end[&amp;quot;event_type&amp;quot;] == &amp;quot;resource_use&amp;quot;]\n             .rename(columns={&amp;#x27;timestamp_dt&amp;#x27;:&amp;#x27;resource_use_start&amp;#x27;}).drop(columns=&amp;quot;event_type&amp;quot;)\n             )\n    \n          resource_use_end = (\n             resource_use_start_and_end[resource_use_start_and_end[&amp;quot;event_type&amp;quot;] == &amp;quot;resource_use_end&amp;quot;]\n             .rename(columns={&amp;#x27;timestamp_dt&amp;#x27;:&amp;#x27;resource_use_end&amp;#x27;})\n             .drop(columns=&amp;quot;event_type&amp;quot;)\n             )\n    \n          resource_use_wide = (\n             resource_use_start.merge(resource_use_end, how=&amp;quot;outer&amp;quot;,\n                                     on=[&amp;quot;P_ID&amp;quot;,&amp;quot;run_number&amp;quot;,&amp;quot;callsign&amp;quot;, &amp;quot;callsign_group&amp;quot;, &amp;quot;registration&amp;quot;])\n                                     .sort_values([&amp;quot;run_number&amp;quot;, &amp;quot;P_ID&amp;quot;])\n                                     )\n    \n          resource_use_wide[&amp;#x27;resource_use_start&amp;#x27;] = pd.to_datetime(resource_use_wide[&amp;#x27;resource_use_start&amp;#x27;])\n          resource_use_wide[&amp;#x27;resource_use_end&amp;#x27;] = pd.to_datetime(resource_use_wide[&amp;#x27;resource_use_end&amp;#x27;])\n    \n          # Get a list of callsign groups that appear in the sim output to iterate through\n          callsign_groups = resource_use_wide[&amp;quot;callsign_group&amp;quot;].unique()\n    \n          # Initialise an empty list to store all instances of overlaps in\n          all_overlaps = []\n    \n          # For each group, identify any overlapping resource usage\n          for callsign_group in callsign_groups:\n    \n             single_callsign = resource_use_wide[resource_use_wide[&amp;quot;callsign_group&amp;quot;]==callsign_group]\n    \n             # Sort by group and start time\n             df_sorted = single_callsign.sort_values(by=[&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;, &amp;quot;resource_use_start&amp;quot;])\n    \n             # Shift end times within each group to compare with the next start\n             df_sorted[&amp;quot;prev_resource_use_start&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;])[&amp;quot;resource_use_start&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_use_end&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;])[&amp;quot;resource_use_end&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_callsign&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;])[&amp;quot;callsign&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_reg&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;])[&amp;quot;registration&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_P_ID&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign_group&amp;quot;])[&amp;quot;P_ID&amp;quot;].shift()\n    \n             # Find overlaps\n             df_sorted[&amp;quot;overlap&amp;quot;] = df_sorted[&amp;quot;resource_use_start&amp;quot;] &amp;lt; df_sorted[&amp;quot;prev_resource_use_end&amp;quot;]\n    \n             # Filter to overlapping rows\n             overlaps = df_sorted[df_sorted[&amp;quot;overlap&amp;quot;]]\n    \n             print(f&amp;quot;Callsign Group {callsign_group} - jobs: {len(single_callsign)}&amp;quot;)\n             print(f&amp;quot;Callsign Group {callsign_group} - overlaps: {len(overlaps)}&amp;quot;)\n    \n             all_overlaps.append(overlaps)\n    \n          all_overlaps_df = pd.concat(all_overlaps)\n    \n          if len(all_overlaps_df)&amp;gt;0:\n             all_overlaps_df.to_csv(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FAILURES.csv&amp;quot;)\n             resource_use_wide.to_csv(&amp;quot;tests/simultaneous_allocation_same_callsigngroup_FULL.csv&amp;quot;)\n    \n    \n&amp;gt;         assert len(all_overlaps_df) == 0, (\n                f&amp;quot;[FAIL - RESOURCE ALLOCATION LOGIC] {len(all_overlaps_df)} instances found of resources from the same callsign group being sent on two or more jobs at once across {len(resource_use_wide)} calls&amp;quot;)\nE               AssertionError: [FAIL - RESOURCE ALLOCATION LOGIC] 8134 instances found of resources from the same callsign group being sent on two or more jobs at once across 96195 calls\nE               assert 8134 == 0\nE                +  where 8134 = len(       P_ID  run_number callsign  ...  prev_resource_reg prev_P_ID overlap\\n48        6           1     CC70  ...      ...    7390.0    True\\n70182  7784          10     CC71  ...             g-daan    7783.0    True\\n\\n[8134 rows x 13 columns])\n\ntests\\test_unittest_model.py:416: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\nCallsign Group 70.0 - jobs: 53731\nCallsign Group 70.0 - overlaps: 7859\nCallsign Group 71.0 - jobs: 22591\nCallsign Group 71.0 - overlaps: 275\nCallsign Group 72.0 - jobs: 19873\nCallsign Group 72.0 - overlaps: 0\n&#34;}], &#34;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource&#34;, &#34;duration&#34;: &#34;837 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_simultaneous_allocation_same_resource&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;837 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;simulation_results =          Unnamed: 0   P_ID  run_number time_type                         event_type  timestamp                timestam...            NaN         09  84.0  Male       EC            y         NaN      NaN      NaN\n\n[1614497 rows x 25 columns]\n\n    @pytest.mark.resources\n    def test_simultaneous_allocation_same_resource(simulation_results):\n       &amp;quot;&amp;quot;&amp;quot;\n       Ensures no single resource is allocated to multiple jobs at the same time.\n    \n       Checks that a specific callsign (i.e., physical unit) is not double-booked.\n       &amp;quot;&amp;quot;&amp;quot;\n       try:\n          if os.path.exists(&amp;quot;tests/simultaneous_allocation_same_resource_FAILURES.csv&amp;quot;):\n             os.remove(&amp;quot;tests/simultaneous_allocation_same_resource_FAILURES.csv&amp;quot;)\n    \n          if os.path.exists(&amp;quot;tests/simultaneous_allocation_same_resource_FULL.csv&amp;quot;):\n             os.remove(&amp;quot;tests/simultaneous_allocation_same_resource_FULL.csv&amp;quot;)\n    \n          results = simulation_results # defined in conftest.py\n    \n          resource_use_start_and_end = (\n             results[results[&amp;quot;event_type&amp;quot;].isin([&amp;quot;resource_use&amp;quot;,&amp;quot;resource_use_end&amp;quot;])]\n             [[&amp;#x27;P_ID&amp;#x27;,&amp;#x27;run_number&amp;#x27;,&amp;#x27;event_type&amp;#x27;,&amp;#x27;callsign&amp;#x27;,&amp;#x27;callsign_group&amp;#x27;,&amp;#x27;registration&amp;#x27;,&amp;#x27;timestamp_dt&amp;#x27;]]\n             )\n    \n          resource_use_start = (\n             resource_use_start_and_end[resource_use_start_and_end[&amp;quot;event_type&amp;quot;] == &amp;quot;resource_use&amp;quot;]\n             .rename(columns={&amp;#x27;timestamp_dt&amp;#x27;:&amp;#x27;resource_use_start&amp;#x27;})\n             .drop(columns=&amp;quot;event_type&amp;quot;)\n             )\n    \n          resource_use_end = (\n             resource_use_start_and_end[resource_use_start_and_end[&amp;quot;event_type&amp;quot;] == &amp;quot;resource_use_end&amp;quot;]\n             .rename(columns={&amp;#x27;timestamp_dt&amp;#x27;:&amp;#x27;resource_use_end&amp;#x27;})\n             .drop(columns=&amp;quot;event_type&amp;quot;)\n             )\n    \n          resource_use_wide = (\n             resource_use_start.merge(resource_use_end, how=&amp;quot;outer&amp;quot;,\n                                     on=[&amp;quot;P_ID&amp;quot;,&amp;quot;run_number&amp;quot;,&amp;quot;callsign&amp;quot;, &amp;quot;callsign_group&amp;quot;, &amp;quot;registration&amp;quot;]\n                                     )\n             .sort_values([&amp;quot;run_number&amp;quot;, &amp;quot;P_ID&amp;quot;]))\n    \n          resource_use_wide[&amp;#x27;resource_use_start&amp;#x27;] = pd.to_datetime(resource_use_wide[&amp;#x27;resource_use_start&amp;#x27;])\n          resource_use_wide[&amp;#x27;resource_use_end&amp;#x27;] = pd.to_datetime(resource_use_wide[&amp;#x27;resource_use_end&amp;#x27;])\n    \n          callsigns = resource_use_wide[&amp;quot;callsign&amp;quot;].unique()\n    \n          all_overlaps = []\n    \n          for callsign in callsigns:\n    \n             single_callsign = resource_use_wide[resource_use_wide[&amp;quot;callsign&amp;quot;]==callsign]\n    \n             assert len(single_callsign) &amp;gt; 0, f&amp;quot;Single callsign df for {callsign} is empty&amp;quot;\n    \n             # Sort by group and start time\n             df_sorted = single_callsign.sort_values(by=[&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;, &amp;quot;resource_use_start&amp;quot;])\n             print(df_sorted)\n    \n             # Shift end times within each group to compare with the next start\n             df_sorted[&amp;quot;prev_resource_use_start&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;])[&amp;quot;resource_use_start&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_use_end&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;])[&amp;quot;resource_use_end&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_callsign&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;])[&amp;quot;callsign&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_resource_reg&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;])[&amp;quot;registration&amp;quot;].shift()\n             df_sorted[&amp;quot;prev_P_ID&amp;quot;] = df_sorted.groupby([&amp;quot;run_number&amp;quot;, &amp;quot;callsign&amp;quot;])[&amp;quot;P_ID&amp;quot;].shift()\n    \n             # Find overlaps\n             df_sorted[&amp;quot;overlap&amp;quot;] = df_sorted[&amp;quot;resource_use_start&amp;quot;] &amp;lt; df_sorted[&amp;quot;prev_resource_use_end&amp;quot;]\n    \n             # Filter to overlapping rows\n             overlaps = df_sorted[df_sorted[&amp;quot;overlap&amp;quot;]]\n    \n             print(f&amp;quot;Callsign {callsign} - instances: {len(single_callsign)}&amp;quot;)\n             print(f&amp;quot;Callsign {callsign} - overlaps: {len(overlaps)}&amp;quot;)\n    \n             all_overlaps.append(overlaps)\n    \n          all_overlaps_df = pd.concat(all_overlaps)\n    \n          if len(all_overlaps_df)&amp;gt;0:\n             all_overlaps_df.to_csv(&amp;quot;tests/simultaneous_allocation_same_resource_FAILURES.csv&amp;quot;)\n             resource_use_wide.to_csv(&amp;quot;tests/simultaneous_allocation_same_resource_FULL.csv&amp;quot;)\n    \n&amp;gt;         assert len(all_overlaps_df) == 0, (\n                f&amp;quot;[FAIL - RESOURCE ALLOCATION LOGIC] {len(all_overlaps_df)} instances found of resources being sent on two or more jobs at once across {len(resource_use_wide)} calls&amp;quot;\n                )\nE               AssertionError: [FAIL - RESOURCE ALLOCATION LOGIC] 2515 instances found of resources being sent on two or more jobs at once across 96195 calls\nE               assert 2515 == 0\nE                +  where 2515 = len(        P_ID  run_number callsign  ...  prev_resource_reg prev_P_ID overlap\\n1715     191           1      H70  ...    ...  10659.0    True\\n95967  10667          10     CC70  ...               cc70   10666.0    True\\n\\n[2515 rows x 13 columns])\n\ntests\\test_unittest_model.py:503: AssertionError\n\n----------------------------- Captured stdout call -----------------------------\n        P_ID  run_number  ...  resource_use_start           resource_use_end\n0          1           1  ... 2023-01-01 11:32:00 2023-01-01 13:32:49.952046\n19         3           1  ... 2023-01-01 19:57:00 2023-01-01 21:53:16.301833\n38         5           1  ... 2023-01-01 22:33:06 2023-01-02 00:19:35.411322\n75         9           1  ... 2023-01-02 14:13:00 2023-01-02 16:17:15.467422\n92        11           1  ... 2023-01-02 18:26:06 2023-01-02 19:41:52.677472\n...      ...         ...  ...                 ...                        ...\n96141  10701          10  ... 2026-12-25 08:27:00 2026-12-25 10:10:36.357575\n96149  10704          10  ... 2026-12-25 12:52:06 2026-12-25 14:32:03.160888\n96152  10706          10  ... 2026-12-25 19:39:06 2026-12-25 21:44:16.177201\n96156  10708          10  ... 2026-12-25 21:42:00 2026-12-25 23:57:33.763821\n96162  10712          10  ... 2026-12-26 11:55:00 2026-12-26 14:18:48.119489\n\n[30778 rows x 7 columns]\nCallsign H70 - instances: 30778\nCallsign H70 - overlaps: 1531\n        P_ID  run_number  ...  resource_use_start           resource_use_end\n9          2           1  ... 2023-01-01 12:29:00 2023-01-01 14:34:30.910023\n67         8           1  ... 2023-01-02 11:47:00 2023-01-02 14:24:19.833266\n121       14           1  ... 2023-01-03 09:44:00 2023-01-03 10:46:52.668896\n129       15           1  ... 2023-01-03 10:59:00 2023-01-03 12:16:27.692037\n1592     177           1  ... 2023-01-26 08:30:00 2023-01-26 10:26:45.400526\n...      ...         ...  ...                 ...                        ...\n96121  10694          10  ... 2026-12-24 09:23:00 2026-12-24 10:22:22.940175\n96133  10697          10  ... 2026-12-24 12:26:00 2026-12-24 14:07:11.583111\n96147  10703          10  ... 2026-12-25 09:15:00 2026-12-25 11:29:50.256429\n96164  10713          10  ... 2026-12-26 12:11:00 2026-12-26 13:42:04.641448\n96167  10715          10  ... 2026-12-26 13:50:00 2026-12-26 16:28:14.883409\n\n[18477 rows x 7 columns]\nCallsign H71 - instances: 18477\nCallsign H71 - overlaps: 0\n        P_ID  run_number  ...  resource_use_start           resource_use_end\n48         6           1  ... 2023-01-01 23:41:06 2023-01-02 00:24:56.273001\n102       12           1  ... 2023-01-02 19:38:06 2023-01-02 20:34:34.021946\n201       23           1  ... 2023-01-04 14:59:06 2023-01-04 17:22:14.649201\n239       27           1  ... 2023-01-05 10:55:06 2023-01-05 12:21:54.176637\n276       31           1  ... 2023-01-05 16:32:00 2023-01-05 19:11:26.676154\n...      ...         ...  ...                 ...                        ...\n95959  10666          10  ... 2026-12-20 15:53:06 2026-12-20 17:24:36.923943\n95967  10667          10  ... 2026-12-20 16:55:00 2026-12-20 19:03:36.553225\n96135  10699          10  ... 2026-12-24 19:40:00 2026-12-24 21:11:28.754266\n96150  10705          10  ... 2026-12-25 16:26:06 2026-12-25 17:25:19.984292\n96154  10707          10  ... 2026-12-25 21:22:06 2026-12-25 22:50:26.849327\n\n[22953 rows x 7 columns]\nCallsign CC70 - instances: 22953\nCallsign CC70 - overlaps: 984\n        P_ID  run_number  ...  resource_use_start           resource_use_end\n57         7           1  ... 2023-01-02 10:17:06 2023-01-02 12:05:42.157298\n83        10           1  ... 2023-01-02 15:41:06 2023-01-02 16:35:17.588718\n146       17           1  ... 2023-01-03 13:31:06 2023-01-03 15:42:40.562493\n210       24           1  ... 2023-01-04 16:19:06 2023-01-04 17:35:51.549152\n248       28           1  ... 2023-01-05 11:48:06 2023-01-05 13:16:51.625165\n...      ...         ...  ...                 ...                        ...\n96129  10696          10  ... 2026-12-24 11:49:06 2026-12-24 12:45:59.963499\n96144  10702          10  ... 2026-12-25 08:31:06 2026-12-25 10:17:12.071568\n96160  10711          10  ... 2026-12-26 08:46:06 2026-12-26 11:36:17.345013\n96165  10714          10  ... 2026-12-26 12:54:06 2026-12-26 14:06:45.793755\n96169  10716          10  ... 2026-12-26 17:58:06 2026-12-26 19:02:52.519602\n\n[19873 rows x 7 columns]\nCallsign CC72 - instances: 19873\nCallsign CC72 - overlaps: 0\n        P_ID  run_number  ...  resource_use_start           resource_use_end\n191       22           1  ... 2023-01-04 12:15:06 2023-01-04 13:47:18.163990\n229       26           1  ... 2023-01-05 10:47:06 2023-01-05 12:07:00.047593\n266       30           1  ... 2023-01-05 14:13:06 2023-01-05 15:41:35.753939\n320       36           1  ... 2023-01-06 16:57:06 2023-01-06 17:43:08.921383\n401       45           1  ... 2023-01-08 10:10:06 2023-01-08 10:54:21.815619\n...      ...         ...  ...                 ...                        ...\n95069  10555          10  ... 2026-12-01 12:23:00 2026-12-01 13:41:47.418591\n95112  10560          10  ... 2026-12-02 13:32:00 2026-12-02 14:57:09.913303\n95146  10564          10  ... 2026-12-03 10:25:00 2026-12-03 11:28:26.633996\n95178  10568          10  ... 2026-12-04 12:02:00 2026-12-04 13:21:04.019928\n95243  10576          10  ... 2026-12-06 14:46:00 2026-12-06 17:03:14.622892\n\n[4114 rows x 7 columns]\nCallsign CC71 - instances: 4114\nCallsign CC71 - overlaps: 0\n&#34;}], &#34;tests/test_unittest_model.py::test_no_response_during_off_shift_times&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_no_response_during_off_shift_times&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_no_response_during_off_shift_times&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/test_unittest_model.py::test_no_response_during_service&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/test_unittest_model.py::test_no_response_during_service&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/test_unittest_model.py::test_no_response_during_service&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.--------------------------- Captured stdout teardown ---------------------------\nRemoved cached simulation results: tests/run_results_fixture.csv\nRemoved cached simulation results: data/service_dates.csv\nRemoved cached simulation results: tests/service_dates_fixture.csv\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;=pytest_report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>